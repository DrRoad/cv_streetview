<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Urban Viz</title>


    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">
    <link rel="stylesheet" href="http://cdn.leafletjs.com/leaflet/v0.7.7/leaflet.css" />
    <!-- Font -->
    <link href='https://fonts.googleapis.com/css?family=Jura:400, 300' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto:300,100' rel='stylesheet' type='text/css'>
    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/style.css">


    <!-- JS Libraries -->
    <script type="text/javascript" src="libs/d3.js"></script>
    <script type="text/javascript" src="libs/d3-tip.js"></script>
    <script type="text/javascript" src="libs/hexbin.js"></script>
    <script type="text/javascript" src="libs/queue.min.js"></script>
    <script type="text/javascript" src="libs/jquery-2.1.4.js"></script>
    <script type="text/javascript" src="libs/jquery.jcarousel.js"></script>
    <script type="text/javascript" src="libs/topojson.js"></script>
    <script type="text/javascript" src="libs/bootstrap.js"></script>
    <script type="text/javascript" src="libs/cubehelix.js"></script>

    <script src="http://cdn.leafletjs.com/leaflet-0.7.3/leaflet.js"></script>   
    <script src='https://api.mapbox.com/mapbox.js/v2.2.3/mapbox.js'></script>
    <!-- Custom JavaScript -->

</head>

<body id="page-top" class="index">

    <div class="container">


        <!--START of introduction section-->
        <section id="heading">
            <div class="text-center col-md-12">
                <h1 > Images of the City: <br> A Pattern Language </h1>
                <h2 >
                    Computer Vision Analysis of Urban District Visual Identities
                    <br> Using Google Street View Data
                </h2>
                <p>
                    This is the visualization portal for my thesis project - "Images of the City: A Pattern Language",
                    <br>
                    an exploration of the potential of using large-scale city imagery data set (Google Street View)
                    in understanding and reading the cities.
                </p>
            </div>

        </section>

        <section id="introduction">
            <h1 > 4 Steps, 4 Experiments </h1>
            <!--<p>-->

            <!--A particular focus is placed on the idea of visual similarity in various districts in the-->
            <!--urban space, and its relationship with existing district boundaries, such as those of neighborhoods.-->

            <!--</p>-->
            <div class="row">
                <div class="col-md-3">
                    <div class="col-md-12 imContainer">
                        <img src="illustration/part1.png" href="">
                    </div>
                    <p class="col-md-12">
                        First I will explore the use of city imaginary data in Collecting Spatial Statistic that
                        can be used in the studies of urban planning and design; I will discuss my experiment
                        about mapping urban greenery and mapping building façade colors in 4 American cities.
                    </p>
                    <a href=""> Method </a>
                    <a href=""> Visualization </a>
                </div>

                <div class="col-md-3">
                    <div class="col-md-12 imContainer">
                        <img src="illustration/part2.png" href="">
                    </div>
                    <p class="col-md-12">
                        Then I looked at the problem of visual resemblance particularly, and played with a
                        Convolutional Neural Net and train it to identify visually similarity patterns by
                        recognizing cities / neighborhoods from their google street view images.
                    </p>
                    <a href=""> Method </a>
                    <a href=""> Visualization </a>
                </div>

                <div class="col-md-3">
                    <div class="col-md-12 imContainer">
                        <img src="illustration/part3.png" href="">
                    </div>
                    <p class="col-md-12">
                        Next I will talk about the limitation of existing neighborhood boundaries,
                        and how to redefine the boundaries based on shared visual characteristics,
                        using a bottom-up approach which I call “the discovery of perceptual neighborhoods”
                    </p>
                    <a href=""> Method </a>
                    <a href=""> Visualization </a>
                </div>

                <div class="col-md-3">
                    <div class="col-md-12 imContainer">
                        <img src="illustration/part4.png" href="">
                    </div>
                    <p class="col-md-12">
                        Finally I undertook an exploration into latent urban characteristics that
                        can be reflected visually.
                    </p>
                    <a href=""> Method </a>
                    <a href=""> Visualization </a>
                </div>
            </div>

        </section>

        <!--END of introduction section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of data section-->
        <section id="data">
            <h1 > Data Collection </h1>
            <div class="col-md-2"></div>
            <img src="illustration/data_collection.gif" alt="" class="col-md-4 col-sm-6 col-xs-12">
            <p class="col-md-4">
                The dataset for this research is collected using
                <a href="https://developers.google.com/maps/documentation/streetview/"> Google Street View API</a>
                from 4 American cities: Boston, Chicago, New York and San Francisco. 4 images are sampled from each grid point
                within a 6 km radius region covering the major urban area.
            </p>

        </section>

        <!--END of data section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of statistic section-->
        <section id="statistic" class="row">
            <h1 > Large-scale Spatial Statistic Collection </h1>
            <div class="">
                <h3 class="col-md-12">Semantic Segmentation</h3>
                <img src="illustration/segmentation.jpg" alt="" class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-md-6">

                    In order to retrieve information from images, the first step is to isolate visual elements
                    in images. The method I used here is <a href="http://mi.eng.cam.ac.uk/projects/segnet/">SegNet</a>,
                    a neural network prediction model which calculates the possibility of each pixel in this image
                    being in any of the 12 categories.
                    <br>
                    Simply counting the number of pixels in each class already suffices a lot of tasks such as mapping
                    the coverage of greenery across city region, where I can use the number of tree pixels as a proxy;
                    Also sky area should be interesting because it might correspond to building height or urban density;
                    Building areas should be relevant to study the architectural style etc.

                </p>
            </div>

            <div class="">
                <h3 class="col-md-12">Color Quantization</h3>
                <img src="illustration/extract_color.gif" alt="" class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-md-4">
                    But studying building styles usually involves some additional steps; for example
                    in this case I was looking into the dominant colors of buildings across the city
                    and how that varies from region to region, so I did this by color quantization using
                    <a href="http://scikit-learn.org/stable/modules/clustering.html#mean-shift"> Mean-Shift Algorithm</a>,
                    which was to cluster the RGB values of building façade pixels and extracted the one color
                    that has the highest number of pixels, as the representative color of this coordinate.
                </p>
            </div>

        </section>

        <!--END of statistic section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of parallel section-->
        <section id="parallel">

            <div class="row ">
                <h1 class="col-md-12"> Lots of Images at One Glance </h1>
            </div>

            <div class="row">
                <p class="col-md-4">
                    Wouldn't it be great if a map could tell me what a place looks like?
                    How tall the buildings are; how much plantation the area tends to have;
                    and even what colors people there would like to have on their walls.
                    Actually, the information is already collected somewhere
                    (thanks to Google street view!) and all we need is an algorithmic digest. <br>

                    Brush the axes to see the whether the spatial distribution of visual signals
                    aligns with your conception of these cities.

                </p>
                <div class="col-md-8 metavis">
                    <div id="statsVis" class="col-md-6"></div>

                    <!-- Carousel -->
                    <div class="col-md-12 jcarousel-wrapper" style="width: 700px; float:right">
                        <div class="jcarousel" id="carousel1">
                            <ul class="text-center">
                                <li > </li>
                                <li > </li>
                                <li > </li>
                                <li > </li>
                            </ul>
                        </div>
                        <p class="jcarousel-control-prev">&lsaquo;</p>
                        <p class="jcarousel-control-next">&rsaquo;</p>
                    </div>
                </div>
            </div>

            <ul class="row text-center mainVis" id="mapsdot">
                <li class="col-md-3">
                    <div class="fullwidth map-small map-point"></div>
                    <h4>Boston</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-point"></div>
                    <h4>Chicago</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-point"></div>
                    <h4>New York</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-point"></div>
                    <h4>San Francisco</h4>
                    <!--<hr>-->
                </li>
            </ul>

            <div class="row mainVis">
                <div class="col-md-12" id="parallelVis">  </div>
            </div>
        </section>
        <!--END of parallel section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of gradient section-->
        <section id="gradient">

            <div class="row ">
                <h1 class="col-md-12"> Zooming in </h1>
                <div class="col-md-12 control">
                    <h6> Choose a visual attribute, and a city... </h6>
                    <h3>
                        <select id="sel_cate" class="selectpicker">
                            <option value="color" selected="selected">Main Color</option>
                            <option value="sky">Sky Area</option>
                            <option value="tree">Tree Area</option>
                            <option value="entropy">Visual Entropy</option>
                        </select>
                        <select id="sel_city" class="selectpicker">
                            <option value="boston" selected="selected">Boston</option>
                            <option value="chicago">Chicago</option>
                            <option value="newyork">New York</option>
                            <option value="sanfrancisco">San Francisco</option>
                        </select>
                    </h3>
                </div>
            </div>

            <div class="row">
                <div class="col-lg-12">
                    <div id="mapVis" > </div>
                </div>

            </div>

            <div class="row">
                <h3 > All Maps</h3>
                <img src="illustration/all_maps.jpg" alt="" class="col-md-12">
            </div>


        </section>
        <!--END of gradient section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of recognize section-->
        <section id="recognize">
            <h1> Visual Resemblance in Urban Places </h1>

            <div class="row">
                <h3>Recognizing Cities/Neighborhoods from Street View</h3>
                <img src="illustration/recognize.jpg" alt=""  class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-lg-6">

                    So far we’ve looked at “named”, hand-designed visual features.
                    In order to evaluate visual similarity in a more comprehensive way, much more visual features
                    are needed from each image, and an automated process is required for feature extraction.
                    Thus a convolutional neural nets (CNN) is needed for feature extraction.

                    <br><br>

                    We used <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">AlexNext</a> structure in
                    <a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> framework and trained 2 models to
                    classify images according to their city names and neighborhood names, respectively.
                    The figure above shows how error rate and energy descends as the training epoch increases.
                    Also noticeable is that recognizing neighborhoods is a harder task than cities judging from the final error rates.
                </p>
            </div>

            <div class="row">
                <h3>Epitomic Images for Each City</h3>
                <p class="col-lg-12">
                    So let’s look at what the algorithm has learned and whether it makes sense to human beings.
                    Here I plotted the top 10 confident predictions for each of the 10 cities. It's discernible that
                    those from the same category demonstrate some visual similarities, which generally conform to human's
                    impression about those places.
                </p>
                <img src="illustration/epitome.jpg" alt=""  class="col-lg-12">

            </div>

            <div class="row">
                <h3>Categories that the Algorithm Cannot Distinguish</h3>
                <img src="illustration/spectral_clustering.gif" alt=""  class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-lg-6">

                    Apart from what’s being captured by the algorithm, what the algorithm cannot learn is also
                    interesting to know. Intuitively, some neighborhoods are more similar to each other than others,
                    which might reflect important facts about the cities including zoning, cultural influence, or the
                    trend of urban sprawl. How are we going to discover these?

                    <br><br>

                    Here is a way to evaluate which neighborhoods may look similar to each other. On the left, I recorded
                    all the cases of mis-classification, which formulates a matrix with ground-truth categories ("real"
                    categories of each image) on the X axis and predicted categories on the Y axis. The matrix in turn
                    can be considered as a node-link graph where nodes represent all the categories and links represent
                    the levels of similarities between each pair of categories. Then a
                    <a href="http://scikit-learn.org/stable/modules/clustering.html#spectral-clustering">Spectral Clustering Algorithm</a>
                    can be applied to this graph and cluster the nodes based on how strongly they are linked with each other.
                </p>

            </div>


        </section>
        <!--END of recognize section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of similarity section-->
        <section id="similarity">

            <div class="row ">
                <h1 class="col-md-12"> Which Neighborhoods Look Alike </h1>

                <p class="col-md-6">
                    Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
                    Aenean commodo ligula eget dolor. Aenean massa.
                    Cum sociis natoque penatibus et magnis dis parturient montes,
                    nascetur ridiculus mus. Donec quam felis, ultricies nec,
                    pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim.
                    Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu.
                    In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo.
                    Nullam dictum felis eu pede mollis pretium. Integer
                </p>
                <div class="col-md-12 control">
                    <h3>
                        <button id="force" type="button" class="btn btn-secondary">Start</button>
                    </h3>
                </div>
            </div>

            <div class="row mainVis">
                <div class="col-md-12" id="nodeVis">  </div>
            </div>

            <ul class="row text-center mainVis" id="mapspolygon">
                <li class="col-md-3">
                    <div class="fullwidth map-small map-polygon"></div>
                    <h4>Boston</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-polygon"></div>
                    <h4>Chicago</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-polygon"></div>
                    <h4>New York</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-polygon"></div>
                    <h4>San Francisco</h4>
                    <!--<hr>-->
                </li>
            </ul>

        </section>
        <!--END of similarity section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of appearance section-->
        <section id="appearance">

            <div class="row ">
                <h1 class="col-md-12"> The Appearances of Districts </h1>
                <div class="col-md-12 control">
                    <h6> Choose a city to view images... </h6>
                    <h3>
                        <select id="sel_appearance" class="selectpicker">
                            <option value="" selected="selected">Select One</option>
                            <option value="boston">Boston</option>
                            <option value="chicago">Chicago</option>
                            <option value="newyork">New York</option>
                            <option value="sanfrancisco">San Francisco</option>
                        </select>
                    </h3>
                </div>

                <p class="col-md-6">
                    Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
                    Aenean commodo ligula eget dolor. Aenean massa.
                    Cum sociis natoque penatibus et magnis dis parturient montes,
                    nascetur ridiculus mus. Donec quam felis, ultricies nec,
                    pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim.
                    Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu.
                    In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo.
                    Nullam dictum felis eu pede mollis pretium. Integer
                </p>
            </div>

            <div class="row mainVis">
                <div class="col-md-12" id="appearanceVis">  </div>
            </div>

        </section>
        <!--END of appearance section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of bottomup section-->
        <section id="bottomup">
            <h1> Neighborhood-based Classification is not Good Enough </h1>

            <div class="row">
                <h3>Recognizing Cities/Neighborhoods from Street View</h3>
                <img src="illustration/recognize.jpg" alt=""  class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-lg-6">

                    However
                    1, Visual variances within a same neighborhood defies blanket description;


                    <br><br>

                    We used <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">AlexNext</a> structure in
                    <a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> framework and trained 2 models to
                    classify images according to their city names and neighborhood names, respectively.
                    The figure above shows how error rate and energy descends as the training epoch increases.
                    Also noticeable is that recognizing neighborhoods is a harder task than cities judging from the final error rates.
                </p>
            </div>

            <div class="row">
                <h3>Epitomic Images for Each City</h3>
                <p class="col-lg-12">
                    So let’s look at what the algorithm has learned and whether it makes sense to human beings.
                    Here I plotted the top 10 confident predictions for each of the 10 cities. It's discernible that
                    those from the same category demonstrate some visual similarities, which generally conform to human's
                    impression about those places.
                </p>
                <img src="illustration/epitome.jpg" alt=""  class="col-lg-12">

            </div>

            <div class="row">
                <h3>Categories that the Algorithm Cannot Distinguish</h3>
                <img src="illustration/spectral_clustering.gif" alt=""  class="col-md-6 col-sm-8 col-xs-12">
                <p class="col-lg-6">

                    Apart from what’s being captured by the algorithm, what the algorithm cannot learn is also
                    interesting to know. Intuitively, some neighborhoods are more similar to each other than others,
                    which might reflect important facts about the cities including zoning, cultural influence, or the
                    trend of urban sprawl. How are we going to discover these?

                    <br><br>

                    Here is a way to evaluate which neighborhoods may look similar to each other. On the left, I recorded
                    all the cases of mis-classification, which formulates a matrix with ground-truth categories ("real"
                    categories of each image) on the X axis and predicted categories on the Y axis. The matrix in turn
                    can be considered as a node-link graph where nodes represent all the categories and links represent
                    the levels of similarities between each pair of categories. Then a
                    <a href="http://scikit-learn.org/stable/modules/clustering.html#spectral-clustering">Spectral Clustering Algorithm</a>
                    can be applied to this graph and cluster the nodes based on how strongly they are linked with each other.
                </p>

            </div>


        </section>
        <!--END of bottomup section-->

        <!--||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-->

        <!--START of hierarchy section-->
        <section id="hierarchy">

            <div class="row ">
                <h1 class="col-md-12"> The Structure of Urban Space </h1>

                <p class="col-md-6">
                    Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
                    Aenean commodo ligula eget dolor. Aenean massa.
                    Cum sociis natoque penatibus et magnis dis parturient montes,
                    nascetur ridiculus mus. Donec quam felis, ultricies nec,
                    pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim.
                    Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu.
                    In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo.
                    Nullam dictum felis eu pede mollis pretium. Integer
                </p>
            </div>

            <div class="row mainVis">
                <div class="col-md-12" id="hierarchyVis">  </div>
            </div>

            <ul class="row text-center mainVis" id="mapscluster">
                <li class="col-md-3">
                    <div class="fullwidth map-small map-cluster"></div>
                    <h4>Boston</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-cluster"></div>
                    <h4>Chicago</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-cluster"></div>
                    <h4>New York</h4>
                    <!--<hr>-->
                </li>
                <li class="col-md-3">
                    <div class="fullwidth map-small map-cluster"></div>
                    <h4>San Francisco</h4>
                    <!--<hr>-->
                </li>
            </ul>

            <div class="row mainVis">
                <div class="col-md-12" id="hierarchyVis2">  </div>
            </div>

            <!-- Carousel -->
            <div class="col-md-12 jcarousel-wrapper mainVis" style="float:right">
                <div class="jcarousel" id="carousel2">
                    <ul class="text-center">
                        <li > </li>
                        <li > </li>
                        <li > </li>
                        <li > </li>
                        <li > </li>
                        <li > </li>
                        <li > </li>
                        <li > </li>
                    </ul>
                </div>
                <p class="jcarousel-control-prev">&lsaquo;</p>
                <p class="jcarousel-control-next">&rsaquo;</p>
            </div>

            <!--<div class="col-md-12 control">-->
                <!--<h3>-->
                    <!--<button id="pack" type="button" class="btn btn-secondary">Start</button>-->
                <!--</h3>-->
            <!--</div>-->

        </section>
        <!--END of hierarchy section-->



    </div>
    <script type="text/javascript" src="js/main.js"></script>
    <script type="text/javascript" src="js/mapvis.js"></script>
    <script type="text/javascript" src="js/leafletvis.js"></script>
    <script type="text/javascript" src="js/forcevis.js"></script>
    <script type="text/javascript" src="js/parallelvis.js"></script>
    <script type="text/javascript" src="js/demersvis.js"></script>
    <script type="text/javascript" src="js/treevis.js"></script>
    <!--<script type="text/javascript" src="js/clustervis.js"></script>-->
    <script type="text/javascript" src="js/packvis.js"></script>
</body>    